# Deep Learning History

* A good summary of history can be found [here](http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-4/)

# Deep Learning questions

* What is an auto-encoder? 
* Why do we "auto-encode"? 
* What is a Boltzmann Machine? 
* Why a Boltzmann Machine?
* Why do we use sigmoid for an output function? Why tanh? Why not cosine? Why any function in particular?

## Convolution Neural Network
* What is Convolution ? What problem does it solve in Neural Network ?
* What is the use of Convolution is Neural Network ?
* What is the difference between Convolution and Correlation ?
* Why are CNNs used primarily in imaging and not so much other tasks ?

## Recurrent Neural Networks

## Time Delay Neural Networks

## Backpropagation
* Explain back-propagation
* Derive the back-propagation and weight update ?
* Derive the back-propagation for Recurrent Neural Network, CNN with pooling layer ?
* Is it OK to connect from a Layer 4 output back to a Layer 2 input?
* What is the difference between Neural Network and Deep Neural Network ?
* What is the advantage of Deep Neural Network over Neural Network ?
* What does deep Neural Network Capture ?

  
## Discussion on a recent Deep Learning paper


## Some more questions 

## Dropout
* How to implement dropout ?
* What exactly is a dropout layer ?
* Why do we need a dropout layer ?

* Their intuition when and why some tricks such as max pooling, ReLU, maxout, etc. work. 
 * There are no right answers but it helps to understand their thoughts and research experience.

## Implementation details
* Matrix representation of forward, backward, update operations

## Tips and tricks for Neural Network Training

## Datascience Questions

* [KDNudgnetts datascience questions](http://www.kdnuggets.com/2016/02/21-data-science-interview-questions-answers.html)
